env:
  application:
    name: test
    parallelism: 1

sources:
  #  - type: inline
  #    outputs: [ inline_source ]
  #    schema: "id:bigint, name:string, score:int, money:int"
  #    options:
  #      data: |
  #        [
  #          {"id": 1, "name": "Alice", "score": 100, "money": 1000},
  #          {"id": 2, "name": "Bob", "score": 200, "money": 2000},
  #          {"id": 3, "name": "Charlie", "score": 300, "money": 3000}
  #        ]
  #      rows_per_second: 10
  #      number_of_rows: 100
  #      codecs: json

  - type: faker
    outputs: [ faker_source ]
    schema: "struct<id:bigint, cate:string, text:string, in_bytes:bigint, out_bytes:bigint>"
    rows_per_second: 2
    number_of_rows: 100
    fields: [
      { "name": "id", "type": "int", "min": 1, "max": 1000000, "random": false },
      { "name": "cate", "type": "string", "options": [ "a", "b", null, "c", "d" ] },
      { "name": "text", "type": "string", "regex": "12[a-z]{2}" },
      { "name": "in_bytes", "type": "int", "min": 100, "max": 10000 },
      { "name": "out_bytes", "type": "int", "min": 100, "max": 10000 }
    ]

transforms:
  - type: query
    inputs: [ faker_source ]
    outputs: [ query ]
    sql: "select id, cate, text, concat(cate, '_', text) text2, in_bytes, out_bytes, (in_bytes + out_bytes) bytes, (10 + out_bytes) bytes2 from tbl"
  - type: query
    inputs: [ query ]
    outputs: [ query2 ]
    sql: "select id, cate, text, in_bytes, out_bytes, bytes, bytes2 from tbl"

sinks:
  - type: print
    inputs: [ query ]
    print_mode: log_warn
    encoding:
      codec: json